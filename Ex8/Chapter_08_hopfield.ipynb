{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 8\n",
    "## Hopfield networks\n",
    "\n",
    "    Hand-in bug-free (try \"Kernel\" > \"Restart & Run All\") and including all (textual as well as figural) output via Blackboard before the deadline (see Blackboard).\n",
    "\n",
    "Learning goals:\n",
    "1. Get familiar with energy functions and with updating Hopfield networks by hand\n",
    "1. Implement a Hopfield network that fulfills a constraint\n",
    "1. Implement, train and test a Hopfield network on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import urllib2\n",
    "import scipy.misc as sp\n",
    "import skimage as ski"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Flip-flop  (2 points)\n",
    "Consider a Hopfield network consisting of two variables $x_1$ and $x_2$ with thresholds $\\theta_1 = 0.5$ and $\\theta_2 = 0.5$, and a weight $w_{ij} = -1$. This network implements a so-called flip-flop. \n",
    "1. What is the energy function of this network? *(Write down the standard form of $E(\\mathbf{x})$, insert the values and simplify it.)*\n",
    "1. What are the possible energy levels of this network? *(Given the possible state combinations for $x_1$ and $x_2$ in a Hopfield network, which values can $E(\\mathbf{x})$ have?)*\n",
    "1. What are the stable states of this network?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 1\n",
    "1. $E(x) = \\frac{1}{2}(x_1x_2 - x_1 - x_2)$\n",
    "1. \\begin{array}{ l c r }\n",
    "      x_1 & x_2 & E(x) \\\\\n",
    "      0 & 0 & 0 \\\\\n",
    "      0 & 1 & -0.5 \\\\\n",
    "      1 & 0 & -0.5 \\\\\n",
    "      1 & 1 & -0.5 \\\\\n",
    "    \\end{array}\n",
    "1. The stable states are the local minima. If we look at the previous question, these states are: ($x_1=0$ and $x_2=1, x_1=1 $and $x_2=0, x_1=1$ and $x_2=1$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Hopfield net\n",
    "Consider a Hopfield network with weights\n",
    "\\begin{equation}\n",
    "\\mathbf{W} =\n",
    "\\left[\n",
    "\\begin{array}{llll}\n",
    "0 & -0.2 & -0.4 & 0\\\\\n",
    "-0.2 & 0 & 0.5 & 0.3\\\\\n",
    "-0.4 & 0.5 & 0 & 0.8\\\\\n",
    "0 & 0.3 & 0.8 & 0\n",
    "\\end{array}\n",
    "\\right]\n",
    "\\end{equation}\n",
    "and biases\n",
    "$\\boldsymbol{\\theta} = (-0.5,-0.3,-0.8,0.2)$.\n",
    "1. What is the state of the Hopfield network after one sequential update of the first, second, third and fourth node when we start at the initial node state $\\mathbf{x} = (0,1,1,1)$? \n",
    "1. What do you conclude from your observation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 2  (1 point)\n",
    "1. The state is the same as the initial state\n",
    "1. We conclude that the initial state is a stable state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3 : A Hopfield network that fulfills a constraint (2 points)\n",
    "\n",
    "In this exercise you will run a Hopfield model that converges to a state that fulfills a constraint. \n",
    "\n",
    "1. Implement a function `optimize(n)` which returns a length `n` vector of node states. The constraint it should solve is that all nodes should be set to `0`, except for a single random node set to `1`.\n",
    "1. Show that your function works for different values of `n`.\n",
    "\n",
    "Start from random node states. Choose and implement the necessary weights and biases manually (i.e. you do not train the Hopfield network here). The resulting vector should be the configuration of the network when it has converged to a stable state. Make sure that your implementation fulfills all requirements for Hopfield networks to converge to stable states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The optimization function\n",
    "def optimize(n):\n",
    "    node_states = np.random.randint(2, size=n)\n",
    "    print node_states\n",
    "    weights = np.full((n,n),-2)\n",
    "    for i in range(n):\n",
    "        weights[i,i] = 0\n",
    "    biases = np.repeat(1,n)\n",
    "    E = 1\n",
    "    while E is not 0:\n",
    "        a = np.dot(weights, node_states) + biases\n",
    "        \n",
    "        E = -0.5 * np.dot(np.dot(node_states.T,weights),node_states) - np.dot(node_states.T, biases)\n",
    "\n",
    "    return E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Print solutions\n",
    "print optimize(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Hopfield network on given patterns\n",
    "\n",
    "You will now implement a Hopfield network that learns to reconstruct given images. Here you can *a) ignore the bias term*; and *b) use bipolar nodes*. \n",
    "\n",
    "The next cells load an image, resize it and store it together with a mirrored version of the same image in the variables `x1` and `x2`, which will be stacked in the training data `X`. These are your *input patterns*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The source image\n",
    "f = urllib2.urlopen(\"https://homepages.cae.wisc.edu/~ece533/images/watch.png\")\n",
    "\n",
    "# Read the image\n",
    "x1 = mpimg.imread(f)\n",
    "\n",
    "# Make binary\n",
    "x1 = np.mean(sp.imresize(x1,10),2)\n",
    "x1[x1 < np.mean(x1.flatten())] = -1 # Black\n",
    "x1[x1 >= np.mean(x1.flatten())] = 1 # White\n",
    "x1.astype(\"int32\")\n",
    "\n",
    "# Make duplicate but mirrored second image\n",
    "x2 = np.fliplr(x1)\n",
    "\n",
    "# Flatten images\n",
    "sz = x1.shape\n",
    "X = np.stack((x1.flatten(), x2.flatten()), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "ax[0].imshow(X[:, 0].reshape(sz), cmap=\"gray\")\n",
    "ax[0].set_xticks([], [])\n",
    "ax[0].set_yticks([], [])\n",
    "ax[0].set_title(\"x1\")\n",
    "\n",
    "ax[1].imshow(X[:, 1].reshape(sz), cmap=\"gray\")\n",
    "ax[1].set_xticks([], [])\n",
    "ax[1].set_yticks([], [])\n",
    "ax[1].set_title(\"x2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Hopfield training  (1 point)\n",
    "Write a function `hopfield_train(X)` which takes the $n$ *input patterns* `X` (shape $(m,n)$) as argument and returns the weight matrix `w` for a trained Hopfield network with $m$ nodes. Initialize the weights with zeros and then implement the learning rule for the weights. Again, make sure that your network fulfills the requirements for Hopfield network convergence. \n",
    "\n",
    "Note that you can write the weight update term per *input pattern* in a single line using the dot product. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hopfield training\n",
    "def hopfield_train(X):\n",
    "    m, n = X.shape\n",
    "\n",
    "    # Initialize weights\n",
    "                  \n",
    "    # Hebbian learning\n",
    "    \n",
    "    # Avoid self-connections (diagonal)\n",
    "        \n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5  (1 points)\n",
    "Write a function `hopfield_test(X, w, n_epochs)` which takes the $n$ initial states `Y` (shape $(m,n)$) and the learned weights `w` and updates all units in random order for `n_epochs` times (i.e., which \"runs\" your trained Hopfield network for `n_epochs` rounds). The return value should be the updated states `Y` of the Hopfield network. Make sure that your iteration fulfills the requirements for Hopfield network convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hopfield testing\n",
    "def hopfield_test(X, w, n_epochs=10):\n",
    "    \n",
    "    # Loop over epochs\n",
    "        \n",
    "        # Loop over examples\n",
    "        \n",
    "            # Loop over nodes\n",
    "\n",
    "                # Update node\n",
    "            \n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6  (1 points)\n",
    "Train your hopfield network on the two *input patterns* in `X` and save the weights. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run hopfield training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7 (2 points)\n",
    "\n",
    "Test whether your trained Hopfield net can reconstruct the original images when starting from different degrees of corruption (which means randomly changing the pattern's node states). Make use of the function `corrupt_images` for this. \n",
    "\n",
    "1. Choose 4 degrees of corruption (between min: 10%, max: 100%) you want to test. Corrupt the original input images in `X` accordingly.  \n",
    "1. Run your trained Hopfield network with the corrupted images as input. It may not need to run for long time. \n",
    "1. For both patterns show the original, the corrupted and the reconstructed images next to each other. \n",
    "1. For each of the degrees of corruption, comment on what you see. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def corrupt_images(X, percentage=25):\n",
    "    Xhat = X.copy()\n",
    "    n_pixels = int(X.shape[0]*percentage/100)\n",
    "    for i_example in range(X.shape[1]):\n",
    "        idx = np.random.permutation(X.shape[0])[:n_pixels]\n",
    "        Xhat[idx, i_example] = 2 * np.random.randint(0, 2, n_pixels) - 1\n",
    "    return Xhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Corrupt images\n",
    "\n",
    "# Test associative memory properties\n",
    "\n",
    "# Plot results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write comments here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Corrupt images\n",
    "\n",
    "# Test associative memory properties\n",
    "\n",
    "# Plot results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Write comments here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Corrupt images\n",
    "\n",
    "# Test associative memory properties\n",
    "\n",
    "# Plot results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Write comments here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Corrupt images\n",
    "\n",
    "# Test associative memory properties\n",
    "\n",
    "# Plot results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Write comments here."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
